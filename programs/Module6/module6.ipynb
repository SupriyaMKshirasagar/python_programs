{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Prelabeled Dataset\n",
    "   To import and load this MNIST dataset( a dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.datasets import mnist\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) You would load the required layers to build your digit classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "import numpy as np\n",
    "import np_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Multiple methods for data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the reshape and normalize the dataset for your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape in form of (60000, 28, 28, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n",
    "#normalize to get data in range of 0-1\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "number_of_classes = 10\n",
    "y_train = utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = utils.to_categorical(y_test, number_of_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) .add() Method in keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Compile() Method in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 28s 88ms/step - loss: 0.5052 - accuracy: 0.8377 - val_loss: 0.0956 - val_accuracy: 0.9726\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 26s 88ms/step - loss: 0.1679 - accuracy: 0.9487 - val_loss: 0.0603 - val_accuracy: 0.9808\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 26s 86ms/step - loss: 0.1248 - accuracy: 0.9628 - val_loss: 0.0452 - val_accuracy: 0.9866\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 26s 87ms/step - loss: 0.1067 - accuracy: 0.9674 - val_loss: 0.0414 - val_accuracy: 0.9868\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 26s 87ms/step - loss: 0.0926 - accuracy: 0.9728 - val_loss: 0.0340 - val_accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1aff92d8580>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "# .Fit() Method [u can train keras models on numpy arrays using .fit()]\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 202ms/step\n",
      "Predicted Digit: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "img = cv2.imread('D:/python_programs/programs/Module6/number4.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# resize image\n",
    "resized = cv2.resize(img, (28,28), interpolation = cv2.INTER_AREA)\n",
    "img = np.resize(resized, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)\n",
    "#y_pred = model.predict(im2arr)\n",
    "#print(y_pred)\n",
    "y_pred = model.predict(im2arr)\n",
    "digit = np.argmax(y_pred)\n",
    "\n",
    "print(\"Predicted Digit:\", digit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras with Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "99/99 [==============================] - 2s 2ms/step - loss: 0.4661\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.2589\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0855\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0219\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0168\n",
      "Epoch 81/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1af986fb580>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate synthetic timeseries data\n",
    "def generate_timeseries_data(n_steps):\n",
    "    time = np.linspace(0, 2*np.pi, n_steps)\n",
    "    data = np.sin(time) + np.random.normal(0, 0.1, n_steps)\n",
    "    return data\n",
    "\n",
    "n_steps = 100\n",
    "data = generate_timeseries_data(n_steps)\n",
    "\n",
    "# Prepare data for LSTM (input and target)\n",
    "X = data[:-1]\n",
    "y = data[1:]\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X = X.reshape(-1, 1, 1)\n",
    "\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras with reinforcement learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7304\\1072288837.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Train Q-learning agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mq_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Test the agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7304\\1072288837.py\u001b[0m in \u001b[0;36mq_learning\u001b[1;34m(env, episodes, alpha, gamma, epsilon)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning(env, episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    n_actions = env.action_space.n\n",
    "    n_states = env.observation_space.shape[0]\n",
    "    q_table = np.zeros((n_states, n_actions))\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state, :])\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            q_next = np.max(q_table[next_state, :])\n",
    "            q_table[state, action] = (1 - alpha) * q_table[state, action] + alpha * (reward + gamma * q_next)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "    return q_table\n",
    "\n",
    "# Train Q-learning agent\n",
    "q_table = q_learning(env)\n",
    "\n",
    "# Test the agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(q_table[state, :])\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    state = next_state\n",
    "\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras with Support Vector Machine(SVM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 1.0\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3333 - accuracy: 0.3000\n",
      "SVM-like model accuracy: 0.30000001192092896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the SVM model using SVC from scikit-learn\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(\"SVM accuracy:\", accuracy)\n",
    "\n",
    "# Alternatively, you can use Keras to build an SVM-like model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=4, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='hinge', metrics=['accuracy'])\n",
    "\n",
    "# Train the SVM-like model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Evaluate the SVM-like model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"SVM-like model accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data, defining Training models and predict results in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 69ms/step - loss: 1.7195 - accuracy: 0.3519 - val_loss: 1.9652 - val_accuracy: 0.1667\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5544 - accuracy: 0.3519 - val_loss: 1.7730 - val_accuracy: 0.1667\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.4197 - accuracy: 0.3519 - val_loss: 1.6014 - val_accuracy: 0.1667\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.2960 - accuracy: 0.3519 - val_loss: 1.4575 - val_accuracy: 0.1667\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2039 - accuracy: 0.3519 - val_loss: 1.3366 - val_accuracy: 0.1667\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1197 - accuracy: 0.3519 - val_loss: 1.2423 - val_accuracy: 0.1667\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0642 - accuracy: 0.3611 - val_loss: 1.1677 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0187 - accuracy: 0.4537 - val_loss: 1.1135 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9881 - accuracy: 0.5185 - val_loss: 1.0737 - val_accuracy: 0.1667\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9660 - accuracy: 0.5556 - val_loss: 1.0454 - val_accuracy: 0.1667\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9496 - accuracy: 0.5463 - val_loss: 1.0246 - val_accuracy: 0.1667\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9375 - accuracy: 0.5370 - val_loss: 1.0081 - val_accuracy: 0.1667\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9274 - accuracy: 0.5278 - val_loss: 0.9954 - val_accuracy: 0.1667\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9182 - accuracy: 0.5185 - val_loss: 0.9867 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9078 - accuracy: 0.5463 - val_loss: 0.9786 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8985 - accuracy: 0.5463 - val_loss: 0.9720 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8895 - accuracy: 0.5463 - val_loss: 0.9645 - val_accuracy: 0.2500\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8795 - accuracy: 0.5463 - val_loss: 0.9571 - val_accuracy: 0.1667\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8702 - accuracy: 0.5556 - val_loss: 0.9508 - val_accuracy: 0.1667\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8607 - accuracy: 0.5833 - val_loss: 0.9445 - val_accuracy: 0.1667\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8515 - accuracy: 0.5926 - val_loss: 0.9391 - val_accuracy: 0.1667\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8432 - accuracy: 0.5833 - val_loss: 0.9334 - val_accuracy: 0.1667\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8343 - accuracy: 0.5833 - val_loss: 0.9278 - val_accuracy: 0.1667\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8261 - accuracy: 0.5741 - val_loss: 0.9221 - val_accuracy: 0.2500\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8175 - accuracy: 0.5833 - val_loss: 0.9152 - val_accuracy: 0.1667\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8090 - accuracy: 0.5926 - val_loss: 0.9089 - val_accuracy: 0.1667\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8007 - accuracy: 0.5926 - val_loss: 0.9021 - val_accuracy: 0.1667\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7932 - accuracy: 0.5926 - val_loss: 0.8956 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7846 - accuracy: 0.6019 - val_loss: 0.8895 - val_accuracy: 0.2500\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7776 - accuracy: 0.5833 - val_loss: 0.8841 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7689 - accuracy: 0.5833 - val_loss: 0.8776 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7611 - accuracy: 0.6111 - val_loss: 0.8709 - val_accuracy: 0.1667\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7540 - accuracy: 0.6111 - val_loss: 0.8648 - val_accuracy: 0.1667\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7472 - accuracy: 0.6019 - val_loss: 0.8590 - val_accuracy: 0.1667\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7397 - accuracy: 0.6019 - val_loss: 0.8529 - val_accuracy: 0.1667\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7329 - accuracy: 0.6019 - val_loss: 0.8480 - val_accuracy: 0.1667\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7253 - accuracy: 0.6296 - val_loss: 0.8427 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7192 - accuracy: 0.6204 - val_loss: 0.8374 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7119 - accuracy: 0.5926 - val_loss: 0.8333 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7053 - accuracy: 0.6019 - val_loss: 0.8287 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6985 - accuracy: 0.6389 - val_loss: 0.8238 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6927 - accuracy: 0.6389 - val_loss: 0.8190 - val_accuracy: 0.2500\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6870 - accuracy: 0.6389 - val_loss: 0.8142 - val_accuracy: 0.2500\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6809 - accuracy: 0.6389 - val_loss: 0.8089 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6740 - accuracy: 0.6296 - val_loss: 0.8029 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6685 - accuracy: 0.6019 - val_loss: 0.7969 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6637 - accuracy: 0.6296 - val_loss: 0.7922 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6577 - accuracy: 0.6296 - val_loss: 0.7885 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6526 - accuracy: 0.6296 - val_loss: 0.7856 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6471 - accuracy: 0.6296 - val_loss: 0.7821 - val_accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6306 - accuracy: 0.6667\n",
      "Test Loss: 0.6306253671646118\n",
      "Test Accuracy: 0.6666666865348816\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Predicted Classes: ['setosa', 'virginica', 'versicolor']\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#PROCESS THE MODULE....DEFINE THE DATA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Create the MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = [[5.1, 3.5, 1.4, 0.2], [6.4, 3.2, 4.5, 1.5], [7.3, 2.9, 6.3, 1.8]]\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = [iris.target_names[pred.argmax()] for pred in predictions]\n",
    "print(\"Predicted Classes:\", predicted_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 28s 88ms/step - loss: 0.4664 - accuracy: 0.8508 - val_loss: 0.0805 - val_accuracy: 0.9749\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 26s 86ms/step - loss: 0.1540 - accuracy: 0.9529 - val_loss: 0.0517 - val_accuracy: 0.9827\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 26s 87ms/step - loss: 0.1164 - accuracy: 0.9650 - val_loss: 0.0451 - val_accuracy: 0.9857\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 26s 88ms/step - loss: 0.1009 - accuracy: 0.9693 - val_loss: 0.0403 - val_accuracy: 0.9878\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 27s 89ms/step - loss: 0.0865 - accuracy: 0.9741 - val_loss: 0.0371 - val_accuracy: 0.9876\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Predicted Digit: 8\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "import numpy as np\n",
    "import np_utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#reshape in form of (60000, 28, 28, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n",
    "#normalize to get data in range of 0-1\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "number_of_classes = 10\n",
    "y_train = utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "y_train.shape\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "# .Fit() Method [u can train keras models on numpy arrays using .fit()]\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5,batch_size=200)\n",
    "\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread('D:/python_programs/programs/Module6/number4.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# resize image\n",
    "resized = cv2.resize(img, (28,28), interpolation = cv2.INTER_AREA)\n",
    "img = np.resize(resized, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)\n",
    "#y_pred = model.predict(im2arr)\n",
    "#print(y_pred)\n",
    "y_pred = model.predict(im2arr)\n",
    "digit = np.argmax(y_pred)\n",
    "\n",
    "print(\"Predicted Digit:\", digit)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7304\\2238968146.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    296\u001b[0m            [5, 6]])\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "model = Sequential()\n",
    "Dense(24, input_dim=state_size, activation='relu')\n",
    "Dense(24, activation='relu')\n",
    "Dense(action_size, activation='linear')\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "memory = deque(maxlen=2000)\n",
    "gamma, epsilon, epsilon_min, epsilon_decay = 0.95, 1.0, 0.01, 0.995\n",
    "batch_size, n_episodes = 5, 10\n",
    "for episode in range(n_episodes):\n",
    "    state, total_reward = env.reset(),0\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    for time in range(50):\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(model.predict(state)[0])\n",
    "        \n",
    "next_state, reward, done, _ = env.step(action)\n",
    "next_state = np.reshape(next_state, [1, state_size])\n",
    "total_reward += reward\n",
    "memory.append((state, action, reward, next_state, done))\n",
    "state = next_state\n",
    "if done:\n",
    "    print(f\"Episode: {episode + 1}, Score: {time + 1}, Epsilon: {epsilon:.2f}\")\n",
    "        \n",
    "    if len(memory) > batch_size:\n",
    "        minibatch = random.sample(memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward + gamma * np.amax(model.predict(next_state)[0])\n",
    "            target_f = model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            model.fit(state, target_f, epochs=1, verbose=0)\n",
    "epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import  keras\n",
    "from keras import layers\n",
    "\n",
    "model=keras.Sequential(\n",
    "[\n",
    "    layers.Dense(2,activation=\"relu\",name=\"layer1\"),\n",
    "    layers.Dense(3,activation=\"relu\",name=\"layer2\"),\n",
    "    layers.Dense(4,name=\"layer4\"),\n",
    "]\n",
    ")\n",
    "\n",
    "x=tf.ones((3,3))\n",
    "y=model(x)\n",
    "\n",
    "\n",
    "model.pop()\n",
    "print(len(model.layers))\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Dense(5,activation=\"relu\",name=\"layer5\"))\n",
    "print(len(model.layers))\n",
    "\n",
    "#layer=layers.Dense(5)\n",
    "layer.weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "x=tf.ones((1,4))\n",
    "y=layer(x)\n",
    "\n",
    "print(len(model.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 2)                 8         \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 3)                 9         \n",
      "                                                                 \n",
      " layer5 (Dense)              multiple                  20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37 (148.00 Byte)\n",
      "Trainable params: 37 (148.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
