{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Prelabeled Dataset\n",
    "   To import and load this MNIST dataset( a dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.datasets import mnist\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) You would load the required layers to build your digit classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "import numpy as np\n",
    "import np_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Multiple methods for data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the reshape and normalize the dataset for your requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape in form of (60000, 28, 28, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n",
    "#normalize to get data in range of 0-1\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "number_of_classes = 10\n",
    "y_train = utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = utils.to_categorical(y_test, number_of_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) .add() Method in keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Compile() Method in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 26s 82ms/step - loss: 0.4675 - accuracy: 0.8499 - val_loss: 0.0891 - val_accuracy: 0.9722\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 26s 86ms/step - loss: 0.1575 - accuracy: 0.9521 - val_loss: 0.0521 - val_accuracy: 0.9822\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 26s 85ms/step - loss: 0.1184 - accuracy: 0.9641 - val_loss: 0.0417 - val_accuracy: 0.9864\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 25s 85ms/step - loss: 0.1004 - accuracy: 0.9697 - val_loss: 0.0364 - val_accuracy: 0.9871\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 25s 85ms/step - loss: 0.0886 - accuracy: 0.9740 - val_loss: 0.0323 - val_accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28e12de2b20>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "# .Fit() Method [u can train keras models on numpy arrays using .fit()]\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n",
      "Predicted Digit: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "img = cv2.imread('D:/python_programs/programs/Module6/num3.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# resize image\n",
    "resized = cv2.resize(img, (28,28), interpolation = cv2.INTER_AREA)\n",
    "img = np.resize(resized, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)\n",
    "#y_pred = model.predict(im2arr)\n",
    "#print(y_pred)\n",
    "y_pred = model.predict(im2arr)\n",
    "digit = np.argmax(y_pred)\n",
    "\n",
    "print(\"Predicted Digit:\", digit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras with Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "99/99 [==============================] - 2s 2ms/step - loss: 0.3358\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.1331\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0303\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0175\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0175\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0177\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0175\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0182\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0179\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0179\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0184\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0175\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0175\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0189\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0181\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0180\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0183\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0184\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0175\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0179\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0175\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0182\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0177\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0177\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0179\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 81/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0177\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0179\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0177\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0180\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.0177\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.0177\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0179\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28e132c3f70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate synthetic timeseries data\n",
    "def generate_timeseries_data(n_steps):\n",
    "    time = np.linspace(0, 2*np.pi, n_steps)\n",
    "    data = np.sin(time) + np.random.normal(0, 0.1, n_steps)\n",
    "    return data\n",
    "\n",
    "n_steps = 100\n",
    "data = generate_timeseries_data(n_steps)\n",
    "\n",
    "# Prepare data for LSTM (input and target)\n",
    "X = data[:-1]\n",
    "y = data[1:]\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X = X.reshape(-1, 1, 1)\n",
    "\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras with reinforcement learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_692\\1072288837.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Train Q-learning agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mq_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Test the agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_692\\1072288837.py\u001b[0m in \u001b[0;36mq_learning\u001b[1;34m(env, episodes, alpha, gamma, epsilon)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mq_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning(env, episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    n_actions = env.action_space.n\n",
    "    n_states = env.observation_space.shape[0]\n",
    "    q_table = np.zeros((n_states, n_actions))\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state, :])\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            q_next = np.max(q_table[next_state, :])\n",
    "            q_table[state, action] = (1 - alpha) * q_table[state, action] + alpha * (reward + gamma * q_next)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "    return q_table\n",
    "\n",
    "# Train Q-learning agent\n",
    "q_table = q_learning(env)\n",
    "\n",
    "# Test the agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(q_table[state, :])\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    state = next_state\n",
    "\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras with Support Vector Machine(SVM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 1.0\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.3417\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3333 - accuracy: 0.3000\n",
      "SVM-like model accuracy: 0.30000001192092896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the SVM model using SVC from scikit-learn\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(\"SVM accuracy:\", accuracy)\n",
    "\n",
    "# Alternatively, you can use Keras to build an SVM-like model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=4, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='hinge', metrics=['accuracy'])\n",
    "\n",
    "# Train the SVM-like model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Evaluate the SVM-like model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"SVM-like model accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data, defining Training models and predict results in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 69ms/step - loss: 1.7195 - accuracy: 0.3519 - val_loss: 1.9652 - val_accuracy: 0.1667\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5544 - accuracy: 0.3519 - val_loss: 1.7730 - val_accuracy: 0.1667\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.4197 - accuracy: 0.3519 - val_loss: 1.6014 - val_accuracy: 0.1667\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.2960 - accuracy: 0.3519 - val_loss: 1.4575 - val_accuracy: 0.1667\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2039 - accuracy: 0.3519 - val_loss: 1.3366 - val_accuracy: 0.1667\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1197 - accuracy: 0.3519 - val_loss: 1.2423 - val_accuracy: 0.1667\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0642 - accuracy: 0.3611 - val_loss: 1.1677 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0187 - accuracy: 0.4537 - val_loss: 1.1135 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9881 - accuracy: 0.5185 - val_loss: 1.0737 - val_accuracy: 0.1667\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9660 - accuracy: 0.5556 - val_loss: 1.0454 - val_accuracy: 0.1667\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9496 - accuracy: 0.5463 - val_loss: 1.0246 - val_accuracy: 0.1667\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9375 - accuracy: 0.5370 - val_loss: 1.0081 - val_accuracy: 0.1667\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9274 - accuracy: 0.5278 - val_loss: 0.9954 - val_accuracy: 0.1667\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9182 - accuracy: 0.5185 - val_loss: 0.9867 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9078 - accuracy: 0.5463 - val_loss: 0.9786 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8985 - accuracy: 0.5463 - val_loss: 0.9720 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8895 - accuracy: 0.5463 - val_loss: 0.9645 - val_accuracy: 0.2500\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8795 - accuracy: 0.5463 - val_loss: 0.9571 - val_accuracy: 0.1667\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8702 - accuracy: 0.5556 - val_loss: 0.9508 - val_accuracy: 0.1667\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8607 - accuracy: 0.5833 - val_loss: 0.9445 - val_accuracy: 0.1667\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8515 - accuracy: 0.5926 - val_loss: 0.9391 - val_accuracy: 0.1667\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8432 - accuracy: 0.5833 - val_loss: 0.9334 - val_accuracy: 0.1667\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8343 - accuracy: 0.5833 - val_loss: 0.9278 - val_accuracy: 0.1667\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8261 - accuracy: 0.5741 - val_loss: 0.9221 - val_accuracy: 0.2500\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8175 - accuracy: 0.5833 - val_loss: 0.9152 - val_accuracy: 0.1667\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8090 - accuracy: 0.5926 - val_loss: 0.9089 - val_accuracy: 0.1667\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8007 - accuracy: 0.5926 - val_loss: 0.9021 - val_accuracy: 0.1667\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7932 - accuracy: 0.5926 - val_loss: 0.8956 - val_accuracy: 0.3333\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7846 - accuracy: 0.6019 - val_loss: 0.8895 - val_accuracy: 0.2500\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7776 - accuracy: 0.5833 - val_loss: 0.8841 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.7689 - accuracy: 0.5833 - val_loss: 0.8776 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7611 - accuracy: 0.6111 - val_loss: 0.8709 - val_accuracy: 0.1667\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7540 - accuracy: 0.6111 - val_loss: 0.8648 - val_accuracy: 0.1667\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7472 - accuracy: 0.6019 - val_loss: 0.8590 - val_accuracy: 0.1667\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7397 - accuracy: 0.6019 - val_loss: 0.8529 - val_accuracy: 0.1667\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7329 - accuracy: 0.6019 - val_loss: 0.8480 - val_accuracy: 0.1667\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7253 - accuracy: 0.6296 - val_loss: 0.8427 - val_accuracy: 0.3333\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7192 - accuracy: 0.6204 - val_loss: 0.8374 - val_accuracy: 0.3333\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7119 - accuracy: 0.5926 - val_loss: 0.8333 - val_accuracy: 0.3333\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7053 - accuracy: 0.6019 - val_loss: 0.8287 - val_accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6985 - accuracy: 0.6389 - val_loss: 0.8238 - val_accuracy: 0.3333\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6927 - accuracy: 0.6389 - val_loss: 0.8190 - val_accuracy: 0.2500\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6870 - accuracy: 0.6389 - val_loss: 0.8142 - val_accuracy: 0.2500\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6809 - accuracy: 0.6389 - val_loss: 0.8089 - val_accuracy: 0.3333\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6740 - accuracy: 0.6296 - val_loss: 0.8029 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6685 - accuracy: 0.6019 - val_loss: 0.7969 - val_accuracy: 0.3333\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6637 - accuracy: 0.6296 - val_loss: 0.7922 - val_accuracy: 0.3333\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6577 - accuracy: 0.6296 - val_loss: 0.7885 - val_accuracy: 0.3333\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6526 - accuracy: 0.6296 - val_loss: 0.7856 - val_accuracy: 0.3333\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6471 - accuracy: 0.6296 - val_loss: 0.7821 - val_accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6306 - accuracy: 0.6667\n",
      "Test Loss: 0.6306253671646118\n",
      "Test Accuracy: 0.6666666865348816\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Predicted Classes: ['setosa', 'virginica', 'versicolor']\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#PROCESS THE MODULE....DEFINE THE DATA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Create the MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = [[5.1, 3.5, 1.4, 0.2], [6.4, 3.2, 4.5, 1.5], [7.3, 2.9, 6.3, 1.8]]\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = [iris.target_names[pred.argmax()] for pred in predictions]\n",
    "print(\"Predicted Classes:\", predicted_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 27s 85ms/step - loss: 0.4784 - accuracy: 0.8457 - val_loss: 0.0797 - val_accuracy: 0.9745\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 25s 84ms/step - loss: 0.1555 - accuracy: 0.9529 - val_loss: 0.0548 - val_accuracy: 0.9815\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 26s 86ms/step - loss: 0.1197 - accuracy: 0.9636 - val_loss: 0.0395 - val_accuracy: 0.9861\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 26s 87ms/step - loss: 0.0978 - accuracy: 0.9695 - val_loss: 0.0335 - val_accuracy: 0.9882\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 26s 87ms/step - loss: 0.0884 - accuracy: 0.9728 - val_loss: 0.0338 - val_accuracy: 0.9881\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Predicted Digit: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import cv2\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "number_of_classes = 10\n",
    "y_train = to_categorical(y_train, number_of_classes)\n",
    "y_test = to_categorical(y_test, number_of_classes)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=200)\n",
    "\n",
    "# Load and preprocess the test image\n",
    "img = cv2.imread('D:/python_programs/programs/Module6/number1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "resized = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "img = np.resize(resized, (28, 28, 1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1, 28, 28, 1)\n",
    "\n",
    "# Make predictions and get the digit output\n",
    "y_pred = model.predict(im2arr)\n",
    "digit = np.argmax(y_pred)\n",
    "\n",
    "print(\"Predicted Digit:\", digit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 38s 100ms/step - loss: 0.4834 - accuracy: 0.8430 - val_loss: 0.0836 - val_accuracy: 0.9743\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 26s 87ms/step - loss: 0.1552 - accuracy: 0.9535 - val_loss: 0.0504 - val_accuracy: 0.9841\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 43s 145ms/step - loss: 0.1175 - accuracy: 0.9640 - val_loss: 0.0452 - val_accuracy: 0.9856\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 50s 166ms/step - loss: 0.0981 - accuracy: 0.9703 - val_loss: 0.0392 - val_accuracy: 0.9873\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 51s 172ms/step - loss: 0.0903 - accuracy: 0.9729 - val_loss: 0.0319 - val_accuracy: 0.9892\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2244\\2309005692.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# resize image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mresized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mim2arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "import numpy as np\n",
    "import np_utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#reshape in form of (60000, 28, 28, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n",
    "#normalize to get data in range of 0-1\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "number_of_classes = 10\n",
    "y_train = utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "y_train.shape\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "# .Fit() Method [u can train keras models on numpy arrays using .fit()]\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5,batch_size=200)\n",
    "\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread('D:/python_programs/programs/Module6/num3.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# resize image\n",
    "resized = cv2.resize(img, (28,28), interpolation = cv2.INTER_AREA)\n",
    "img = np.resize(resized, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)\n",
    "#y_pred = model.predict(im2arr)\n",
    "#print(y_pred)\n",
    "y_pred = model.predict(im2arr)\n",
    "digit = np.argmax(y_pred)\n",
    "\n",
    "print(\"Predicted Digit:\", digit)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
